import tempfile
from share_btn import community_icon_html, loading_icon_html, share_js, save_js
import huggingface_hub
import gradio as gr
# from gill import utils
# from gill import models
# æ²¡æœ‰ç”¨åˆ°å‘€
# import evals.utils as utils
# import evals.models as models
import utils
import models
import matplotlib.pyplot as plt
from PIL import Image
import torch
import numpy as np
import os
# HF Transfer åŠŸèƒ½å…è®¸ç”¨æˆ·åœ¨ Hugging Face Hub ä¸Šç¼“å­˜æ¨¡å‹ï¼Œå¹¶åœ¨éœ€è¦æ—¶è‡ªåŠ¨ä»ç¼“å­˜ä¸­åŠ è½½æ¨¡å‹ã€‚
# ç¦ç”¨è¿™ä¸ªåŠŸèƒ½æ„å‘³ç€åœ¨åŠ è½½æ¨¡å‹æ—¶ï¼Œä¸ä¼šä½¿ç”¨ HF Transfer åŠŸèƒ½ï¼Œè€Œæ˜¯ç›´æ¥ä»è¿œç¨‹ä¸‹è½½æ¨¡å‹
os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "False"

# #save-btnã€#share-btn åˆ†åˆ«è®¾ç½®äº† id ä¸º save-btn å’Œ share-btn çš„æŒ‰é’®å…ƒç´ çš„èƒŒæ™¯æ¸å˜é¢œè‰²ã€‚
css = """
    # è®¾ç½® id ä¸º chatbot çš„å…ƒç´ çš„æœ€å°é«˜åº¦ä¸º 300pxï¼Œç¡®ä¿èŠå¤©æœºå™¨äººç•Œé¢çš„é«˜åº¦ä¸ä¼šå°äº 300pxã€‚
    #chatbot { min-height: 300px; }
    # #save-btnã€#share-btn åˆ†åˆ«è®¾ç½®äº† id ä¸º save-btn å’Œ share-btn çš„æŒ‰é’®å…ƒç´ çš„èƒŒæ™¯æ¸å˜é¢œè‰²ã€‚
    # å½“é¼ æ ‡æ‚¬åœåœ¨æŒ‰é’®ä¸Šæ—¶ï¼ŒèƒŒæ™¯é¢œè‰²ä¼šå‘ç”Ÿå˜åŒ–ï¼Œé‡‡ç”¨ä¸åŒçš„æ¸å˜é¢œè‰²ã€‚
    #save-btn {
        background-image: linear-gradient(to right bottom, rgba(130,217,244, 0.9), rgba(158,231,214, 1.0));
    }
    #save-btn:hover {
        background-image: linear-gradient(to right bottom, rgba(110,197,224, 0.9), rgba(138,211,194, 1.0));
    }
    #share-btn {
        background-image: linear-gradient(to right bottom, rgba(130,217,244, 0.9), rgba(158,231,214, 1.0));
    }
    #share-btn:hover {
        background-image: linear-gradient(to right bottom, rgba(110,197,224, 0.9), rgba(138,211,194, 1.0));
    }
    # å½“é¼ æ ‡æ‚¬åœåœ¨æŒ‰é’®å›¾ç‰‡ä¸Šæ—¶ï¼Œå–æ¶ˆå›¾ç‰‡çš„æ”¾å¤§æ•ˆæœå¹¶æ¢å¤æ­£å¸¸å¤§å°ã€‚
    #gallery { z-index: 999999; }
    #gallery img:hover {transform: scale(2.3); z-index: 999999; position: relative; padding-right: 30%; padding-bottom: 30%;}
    #gallery button img:hover {transform: none; z-index: 999999; position: relative; padding-right: 0; padding-bottom: 0;}
    # åœ¨ä¸æ”¯æŒé¼ æ ‡æ‚¬åœçš„è®¾å¤‡ä¸Šï¼Œå–æ¶ˆå›¾ç‰‡çš„æ”¾å¤§æ•ˆæœï¼ˆtransform: noneï¼‰ï¼Œæ¢å¤åˆ°åŸå§‹å¤§å°ã€‚
    @media (hover: none) {
        #gallery img:hover {transform: none; z-index: 999999; position: relative; padding-right: 0; 0;}
    }
    .html2canvas-container { width: 3000px !important; height: 3000px !important; }
"""

examples = [
    'examples/car.png',
    'examples/cake.png',
    'examples/house.png',
    'examples/maple leaf.png',
    'examples/train.png',
]

# Download model from HF Hub.
# ckpt_path = huggingface_hub.hf_hub_download(
#    repo_id='jykoh/gill', filename='pretrained_ckpt.pth.tar', local_dir='/data1/ruip/gill/gill-main_1/download')
# decision_model_path = huggingface_hub.hf_hub_download(
#     repo_id='jykoh/gill', filename='decision_model.pth.tar', local_dir='/data1/ruip/gill/gill-main_1/download')
# args_path = huggingface_hub.hf_hub_download(
#    repo_id='jykoh/gill', filename='model_args.json', local_dir='/data1/ruip/gill/gill-main_1/download')
path = '/data1/ruip/gill/gill-main_1/checkpoints/gill_opt'
# model = models.load_gill('./', args_path, ckpt_path, decision_model_path)
model = models.load_gill(path)
print("models load complished\n")
# æ¥å—ä¸¤ä¸ªå‚æ•° state å’Œ image_input
# state æ˜¯ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå…ƒç´ çš„åˆ—è¡¨ï¼Œåˆ†åˆ«è¡¨ç¤ºå¯¹è¯å’ŒèŠå¤©å†å²è®°å½•ï¼›image_input æ˜¯ä¸€ä¸ªä¸Šä¼ çš„å›¾åƒæ–‡ä»¶å¯¹è±¡
def upload_image(state, image_input):
    conversation = state[0]
    chat_history = state[1]
    # ä½¿ç”¨ PIL åº“ä¸­çš„ Image.open() æ–¹æ³•æ‰“å¼€ä¸Šä¼ çš„å›¾åƒæ–‡ä»¶ï¼Œ
    # ç„¶åè°ƒç”¨ resize() æ–¹æ³•å°†å›¾åƒå¤§å°è°ƒæ•´ä¸º (224, 224) åƒç´ ï¼Œå†è°ƒç”¨ convert('RGB') æ–¹æ³•å°†å›¾åƒè½¬æ¢ä¸º RGB æ¨¡å¼
    input_image = Image.open(image_input.name).resize(
        (224, 224)).convert('RGB')
    # ä¿å­˜å¤„ç†åçš„å›¾åƒï¼Œè¦†ç›–åŸå›¾åƒæ–‡ä»¶ã€‚è¿™ä¸€æ­¥å¯èƒ½æ˜¯ä¸ºäº†å‡å°‘å›¾åƒå°ºå¯¸ï¼Œä»¥èŠ‚çœå­˜å‚¨ç©ºé—´æˆ–åŠ å¿«å¤„ç†é€Ÿåº¦
    input_image.save(image_input.name)  # Overwrite with smaller image.
    # å¤„ç†åçš„å›¾åƒè·¯å¾„ä»¥ <img> æ ‡ç­¾çš„å½¢å¼æ·»åŠ åˆ°å¯¹è¯è®°å½•ä¸­ï¼Œè¯¥æ ‡ç­¾ç”¨äºå°†å›¾åƒæ˜¾ç¤ºåœ¨å¯¹è¯ç•Œé¢ä¸­
    conversation += [(f'<img src="./file={image_input.name}" style="display: inline-block;">', "")]
    # è¿”å›æ›´æ–°åçš„çŠ¶æ€å’Œå¯¹è¯è®°å½•ã€‚l
    return [conversation, chat_history + [input_image, ""]], conversation


def reset():
    return [[], []], []


def reset_last(state):
    # ä½¿ç”¨åˆ‡ç‰‡æ“ä½œ [:-1]ï¼Œå°†æœ€åä¸€æ¡å¯¹è¯ä»å¯¹è¯è®°å½•ä¸­åˆ é™¤ï¼Œå¾—åˆ°æ›´æ–°åçš„å¯¹è¯è®°å½• conversation
    conversation = state[0][:-1]
    # ä½¿ç”¨åˆ‡ç‰‡æ“ä½œ [:-2]ï¼Œå°†æœ€åä¸¤æ¡èŠå¤©å†å²è®°å½•ä»èŠå¤©å†å²ä¸­åˆ é™¤ï¼Œå¾—åˆ°æ›´æ–°åçš„èŠå¤©å†å²è®°å½• chat_history
    chat_history = state[1][:-2]
    return [conversation, chat_history], conversation


def save_image_to_local(image: Image.Image):
    # TODO(jykoh): Update so the url path is used, to prevent repeat saving.
    # æ›´æ–°ä»£ç ï¼Œä½¿ç”¨ URL è·¯å¾„æ¥ä¿å­˜å›¾åƒï¼Œé¿å…é‡å¤ä¿å­˜
    # tempfile._get_candidate_names() æ˜¯ Python ä¸­ tempfile æ¨¡å—å†…éƒ¨çš„ä¸€ä¸ªå‡½æ•°ï¼Œä¸»è¦ç”¨äºç”Ÿæˆä¸´æ—¶æ–‡ä»¶åçš„å€™é€‰åˆ—è¡¨
    # ä½¿ç”¨ next() å‡½æ•°è·å–å…¶ä¸­çš„ç¬¬ä¸€ä¸ªæ–‡ä»¶å
    filename = next(tempfile._get_candidate_names()) + '.png'
    # å°†å›¾åƒ image ä¿å­˜åˆ°è¿™ä¸ªç”Ÿæˆçš„æ–‡ä»¶åä¸­
    image.save(filename)
    return filename

# è¾“å…¥ï¼š
# è¾“å…¥æ–‡æœ¬
# state: è¡¨ç¤ºæ¨¡å‹çš„å½“å‰çŠ¶æ€ï¼Œå¯èƒ½åŒ…å«äº†æ¨¡å‹å†…éƒ¨çš„ä¸€äº›ä¿¡æ¯æˆ–è€…çŠ¶æ€
# ret_scale_factor: è¡¨ç¤ºè¿”å›çš„ç¼©æ”¾å› å­ï¼Œç”¨äºè°ƒæ•´ç”Ÿæˆæ–‡æœ¬çš„è¿”å›é•¿åº¦
# num_words: è¡¨ç¤ºç”Ÿæˆæ–‡æœ¬çš„é•¿åº¦æˆ–è€…å•è¯æ•°ç›®
# temperature: è¡¨ç¤ºæ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§å’Œåˆ›é€ æ€§çš„æ¸©åº¦å‚æ•°ã€‚è¾ƒé«˜çš„æ¸©åº¦ä¼šå¯¼è‡´æ›´åŠ éšæœºå’Œå¤šæ ·åŒ–çš„ç”Ÿæˆç»“æœï¼Œè€Œè¾ƒä½çš„æ¸©åº¦åˆ™ä¼šå€¾å‘äºç”Ÿæˆæ›´åŠ ç¡®å®šæ€§å’Œä¼ ç»Ÿçš„æ–‡æœ¬
def generate_for_prompt(input_text, state, ret_scale_factor, num_words, temperature):
    # torch.Generator ç±»æ¥åˆ›å»ºä¸€ä¸ªç”Ÿæˆå™¨å¯¹è±¡ g_cudaï¼Œå¹¶æŒ‡å®šè¯¥ç”Ÿæˆå™¨åœ¨ CUDA è®¾å¤‡ä¸Šè¿›è¡Œæ“ä½œï¼Œå¹¶æ‰‹åŠ¨è®¾ç½®ç§å­ä¸º 1337
    g_cuda = torch.Generator(device='cuda').manual_seed(1337)
    # Ignore empty inputs.
    if len(input_text) == 0:
        return state, state[0], gr.update(visible=True)
    
    input_prompt = 'Q: ' + input_text + '\nA:'
    conversation = state[0]
    chat_history = state[1]
    print('Generating for', chat_history, flush=True)

    # If an image was uploaded, prepend it to the model. å¦‚æœä¸Šä¼ äº†ä¸€å¼ å›¾ç‰‡ï¼Œå°†å…¶æ·»åŠ åˆ°æ¨¡å‹å‰é¢
    # è¿™é‡Œæˆ‘çš„ç†è§£æ˜¯chat_historyå…¶å®å°±æ˜¯ä¸Šä¼ çš„å›¾ç‰‡ï¼Œå†å²çš„èŠå¤©è®°å½•æ˜¯å›¾ç‰‡
    model_inputs = chat_history
    model_inputs.append(input_prompt)
    # Remove empty text.
    model_inputs = [s for s in model_inputs if s != '']
    # å­˜åœ¨ä¸€å®šçš„æ¸©åº¦è°ƒèŠ‚ç”Ÿæˆæ–‡æœ¬çš„æƒ…å†µä¸‹ï¼Œtop_p çš„å€¼è¢«è°ƒæ•´ä¸º 0.95ã€‚è¿™å¯ä»¥å½±å“æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ—¶å¯¹è¯æ±‡çš„é‡‡æ ·æ–¹å¼ï¼Œè¿›è€Œå½±å“ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§å’Œåˆ›é€ æ€§ã€‚
    top_p = 1.0
    if temperature != 0.0:
        top_p = 0.95

    print('Running model.generate_for_images_and_texts with', model_inputs, flush=True)
    # modelåœ¨å“ªé‡Œ
    model_outputs = model.generate_for_images_and_texts(model_inputs,
                                                        num_words=max(num_words, 1), ret_scale_factor=ret_scale_factor, top_p=top_p,
                                                        temperature=temperature, max_num_rets=1,
                                                        num_inference_steps=50, generator=g_cuda)
    print('model_outputs', model_outputs, ret_scale_factor, flush=True)

    response = ''
    text_outputs = []
    for output_i, p in enumerate(model_outputs):
        if type(p) == str:
            if output_i > 0:
                response += '<br/>'
            # Remove the image tokens for output.
            text_outputs.append(p.replace('[IMG0] [IMG1] [IMG2] [IMG3] [IMG4] [IMG5] [IMG6] [IMG7]', ''))
            response += p
            if len(model_outputs) > 1:
                response += '<br/>'
        elif type(p) == dict:
            # Decide whether to generate or retrieve.
            if p['decision'] is not None and p['decision'][0] == 'gen':
                image = p['gen'][0][0]#.resize((224, 224))
                filename = save_image_to_local(image)
                response += f'<img src="./file={filename}" style="display: inline-block;"><p style="font-size: 12px; color: #555; margin-top: 0;">(Generated)</p>'
            else:
                image = p['ret'][0][0]#.resize((224, 224))
                filename = save_image_to_local(image)
                response += f'<img src="./file={filename}" style="display: inline-block;"><p style="font-size: 12px; color: #555; margin-top: 0;">(Retrieved)</p>'

    chat_history = model_inputs + \
        [' '.join([s for s in model_outputs if type(s) == str]) + '\n']
    # Remove [RET] from outputs.
    conversation.append((input_text, response.replace('[IMG0] [IMG1] [IMG2] [IMG3] [IMG4] [IMG5] [IMG6] [IMG7]', '')))

    # Set input image to None.
    print('state', state, flush=True)
    print('updated state', [conversation, chat_history], flush=True)
    return [conversation, chat_history], conversation, gr.update(visible=True), gr.update(visible=True)

# åˆ›å»ºä¸€ä¸ªgr.Blockså¯¹è±¡ï¼Œç”¨äºåŒ…å«äº¤äº’å¼ç»„ä»¶å¸ƒå±€
with gr.Blocks(css=css) as demo:
    # gr.HTML(""" ... """)ï¼šåœ¨ Blocks ä¸­æ·»åŠ  HTML å†…å®¹ï¼Œç”¨äºå±•ç¤ºä¸€äº›é™æ€æ–‡æœ¬å’Œé“¾æ¥
    gr.HTML("""
        <h1>ğŸŸ GILL</h1>
        <p>This is the official Gradio demo for the GILL model, a model that can process arbitrarily interleaved image and text inputs, and produce image and text outputs.</p>

        <strong>Paper:</strong> <a href="https://arxiv.org/abs/2305.17216" target="_blank">Generating Images with Multimodal Language Models</a>
        <br/>
        <strong>Project Website:</strong> <a href="https://jykoh.com/gill" target="_blank">GILL Website</a>
        <br/>
        <strong>Code and Models:</strong> <a href="https://github.com/kohjingyu/gill" target="_blank">GitHub</a>
        <br/>
        <br/>

        <strong>Tips:</strong>
        <ul>
        <li>Start by inputting either image or text prompts (or both) and chat with GILL to get image-and-text replies.</li>
        <li>Tweak the level of sensitivity to images and text using the parameters on the right.</li>
        <li>Check out cool conversations in the examples or community tab for inspiration and share your own!</li>
        <li>If the model outputs a blank image, it is because Stable Diffusion's safety filter detected inappropriate content. Please try again with a different prompt.</li>
        <li>Outputs may differ slightly from the paper due to slight implementation differences. For reproducing paper results, please use our <a href="https://github.com/kohjingyu/gill" target="_blank">official code</a>.</li>
        <li>For faster inference without waiting in queue, you may duplicate the space and use your own GPU: <a href="https://huggingface.co/spaces/jykoh/gill?duplicate=true"><img style="display: inline-block; margin-top: 0em; margin-bottom: 0em" src="https://img.shields.io/badge/-Duplicate%20Space-blue?labelColor=white&style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAAXNSR0IArs4c6QAAAP5JREFUOE+lk7FqAkEURY+ltunEgFXS2sZGIbXfEPdLlnxJyDdYB62sbbUKpLbVNhyYFzbrrA74YJlh9r079973psed0cvUD4A+4HoCjsA85X0Dfn/RBLBgBDxnQPfAEJgBY+A9gALA4tcbamSzS4xq4FOQAJgCDwV2CPKV8tZAJcAjMMkUe1vX+U+SMhfAJEHasQIWmXNN3abzDwHUrgcRGmYcgKe0bxrblHEB4E/pndMazNpSZGcsZdBlYJcEL9Afo75molJyM2FxmPgmgPqlWNLGfwZGG6UiyEvLzHYDmoPkDDiNm9JR9uboiONcBXrpY1qmgs21x1QwyZcpvxt9NS09PlsPAAAAAElFTkSuQmCC&logoWidth=14" alt="Duplicate Space"></a></li>
        </ul>
    """)
    # åˆ›å»ºä¸€ä¸ªçŠ¶æ€å¯¹è±¡ï¼Œç”¨äºè·Ÿè¸ªå¯¹è¯å†…å®¹å’ŒèŠå¤©å†å²
    gr_state = gr.State([[], []])  # conversation, chat_history
    # åˆ›å»ºä¸€ä¸ªè¡Œå¸ƒå±€ï¼Œåœ¨è¿™ä¸ªå¸ƒå±€ä¸­æ”¾ç½®å¤šä¸ªäº¤äº’å¼ç»„ä»¶ã€‚
    with gr.Row():
        # åˆ›å»ºä¸€ä¸ªåˆ—å¸ƒå±€ï¼Œè®¾ç½®æ¯”ä¾‹å’Œæœ€å°å®½åº¦
        with gr.Column(scale=0.7, min_width=500):
            with gr.Row():
                # åˆ›å»ºä¸€ä¸ªèŠå¤©æœºå™¨äººç»„ä»¶ï¼Œå¹¶è®¾ç½®æ ‡ç­¾
                chatbot = gr.Chatbot(elem_id="chatbot", label="ğŸŸ GILL Chatbot")
            with gr.Row():
                # åˆ›å»ºä¸€ä¸ªä¸Šä¼ æŒ‰é’®ç»„ä»¶ï¼Œç”¨äºä¸Šä¼ å›¾ç‰‡æ–‡ä»¶
                image_btn = gr.UploadButton("ğŸ–¼ï¸ Upload Image", file_types=["image"])
                # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ç»„ä»¶ï¼Œç”¨äºç”¨æˆ·è¾“å…¥ä¿¡æ¯
                text_input = gr.Textbox(label="Message", placeholder="Type a message")
                with gr.Column():
                    submit_btn = gr.Button(
                        "Submit", interactive=True, variant="primary")
                    clear_last_btn = gr.Button("Undo")
                    clear_btn = gr.Button("Reset All")
                    with gr.Row(visible=False) as save_group:
                        save_button = gr.Button("ğŸ’¾ Save Conversation as .png", elem_id="save-btn")

                    with gr.Row(visible=False) as share_group:
                        share_button = gr.Button("ğŸ¤— Share to Community (opens new window)", elem_id="share-btn")

        with gr.Column(scale=0.3, min_width=400):
            ret_scale_factor = gr.Slider(minimum=0.0, maximum=3.0, value=1.3, step=0.1, interactive=True,
                                         label="Frequency multiplier for returning images (higher means more frequent)")
            gr_max_len = gr.Slider(minimum=1, maximum=64, value=32,
                                   step=1, interactive=True, label="Max # of words")
            gr_temperature = gr.Slider(
                minimum=0.0, maximum=1.0, value=0.0, step=0.1, interactive=True, label="Temperature (0 for deterministic, higher for more randomness)")

#            gallery = gr.Gallery(
#                value=[Image.open(e) for e in examples], label="Example Conversations", show_label=True, elem_id="gallery",
#            ).style(grid=[2], height="auto")
            gallery = gr.Gallery(
                value=[Image.open(e) for e in examples], label="Example Conversations", show_label=True, elem_id="gallery",
            )
    text_input.submit(generate_for_prompt, [text_input, gr_state, ret_scale_factor,
                      gr_max_len, gr_temperature], [gr_state, chatbot, share_group, save_group])
    text_input.submit(lambda: "", None, text_input)  # Reset chatbox.
    submit_btn.click(generate_for_prompt, [text_input, gr_state, ret_scale_factor,
                     gr_max_len, gr_temperature], [gr_state, chatbot, share_group, save_group])
    submit_btn.click(lambda: "", None, text_input)  # Reset chatbox.

    image_btn.upload(upload_image, [gr_state, image_btn], [gr_state, chatbot])
    clear_last_btn.click(reset_last, [gr_state], [gr_state, chatbot])
    clear_btn.click(reset, [], [gr_state, chatbot])
#    share_button.click(None, [], [], _js=share_js)
#    save_button.click(None, [], [], _js=save_js)
    share_button.click(None, [], [])
    save_button.click(None, [], [])


demo.queue(concurrency_count=1, api_open=False, max_size=16)
demo.launch(debug=True, server_name="0.0.0.0", share=False)
